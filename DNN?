import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn import metrics
from random import shuffle

data = pd.read_csv('diabetes.csv')

#X = data.drop(['BloodPressure', 'SkinThickness'], axis=1).iloc[:, :8]
X = data.iloc[:, :8]
y = data.iloc[:, 8:]

scaler = MinMaxScaler()
scaler.fit(X)
norm_X = scaler.transform(X)


norm_X_train, norm_X_test, y_train, y_test = train_test_split(norm_X, y, test_size=.2, random_state=108, shuffle=True)
model = Sequential()

leaky_relu = tf.nn.leaky_relu

model.add(Flatten())
model.add(Dense(units=786, activation='leaky_relu'))
model.add(Dense(units=388, activation='leaky_relu'))
model.add(Dense(units=199, activation='leaky_relu'))
#model.add(Dropout(0.2))
model.add(Dense(units=1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

new_history = model.fit(norm_X_train, y_train, epochs=100, verbose=1, validation_split=0.2)


score = model.evaluate(norm_X_train, y_train, verbose=1)
print('정답률 = ', score[1],'loss=', score[0])

score = model.predict(norm_X_test, verbose=1)
print('정답률 = ', score[1],'loss=', score[0])
