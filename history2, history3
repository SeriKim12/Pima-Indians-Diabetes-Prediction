import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.callbacks import EarlyStopping
from sklearn import metrics

data = pd.read_csv('diabetes.csv')

data.corr()
'''
	                        Pregnancies	 Glucose 	BloodPressure	SkinThickness	Insulin   	BMI	    DiabetesPedigreeFunction	Age     	Outcome
Pregnancies	              1.000000	  0.129459	0.141282	    -0.081672 	-0.073535	  0.017683	-0.033523	                0.544341	0.221898
Glucose	                  0.129459  	1.000000	0.152590	    0.057328	   0.331357	  0.221071	0.137337	                0.263514	0.466581
BloodPressure	            0.141282	  0.152590	1.000000	    0.207371	   0.088933	  0.281805	0.041265	                0.239528	0.065068
SkinThickness	           -0.081672 	  0.057328	0.207371	    1.000000	   0.436783	  0.392573	0.183928	               -0.113970	0.074752
Insulin	                 -0.073535	  0.331357	0.088933	    0.436783	   1.000000	  0.197859	0.185071	               -0.042163	0.130548
BMI	                      0.017683	  0.221071  0.281805	    0.392573	   0.197859	  1.000000	0.140647	                0.036242	0.292695
DiabetesPedigreeFunction -0.033523 	  0.137337	0.041265	    0.183928	   0.185071	  0.140647	1.000000	                0.033561	0.173844
Age                      	0.544341	  0.263514	0.239528	    -0.113970	  -0.042163	  0.036242	0.033561	                1.000000	0.238356
Outcome                 	0.221898	  0.466581	0.065068	    0.074752	   0.130548	  0.292695	0.173844	                0.238356	1.000000

'''

X = data.drop(['BloodPressure', 'SkinThickness'], axis=1).iloc[:, :8]
y = data.iloc[:, 8:]

scaler = MinMaxScaler()
scaler.fit(X)
norm_X = scaler.transform(X)


norm_X_train, norm_X_test, y_train, y_test = train_test_split(norm_X, y, test_size=.25)


model = Sequential()


model.add(Flatten())
model.add(Dense(units=12, input_dim=8, activation='relu'))
model.add(Dense(units=8, activation='relu'))
model.add(Dense(units=1, activation='sigmoid'))

model.compile(optimizer='adam', 
              loss='binary_crossentropy',
             metrics=['accuracy'])

earlyStopping = EarlyStopping(verbose = 1, monitor='accuracy', patience=10)

history2 = model.fit(norm_X_train, y, epochs=50, verbose=1, batch_size = 10, validation_split=0.2, callbacks=earlyStopping)
'''
Epoch 1/50
46/46 [==============================] - 0s 3ms/step - loss: 0.7063 - accuracy: 0.4326 - val_loss: 0.6766 - val_accuracy: 0.6983
Epoch 2/50
46/46 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.6043 - val_loss: 0.6228 - val_accuracy: 0.7931
Epoch 3/50
46/46 [==============================] - 0s 1ms/step - loss: 0.6698 - accuracy: 0.6174 - val_loss: 0.6014 - val_accuracy: 0.7931
중간 생략
Epoch 14/50
46/46 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.6196 - val_loss: 0.5734 - val_accuracy: 0.7931
Epoch 15/50
46/46 [==============================] - 0s 1ms/step - loss: 0.6609 - accuracy: 0.6196 - val_loss: 0.5736 - val_accuracy: 0.7931
Epoch 15: early stopping
'''


history3 = model.fit(norm_X_train, y, epochs=300, verbose=1, batch_size = 10, validation_split=0.2)
'''
Epoch 1/300
46/46 [==============================] - 0s 1ms/step - loss: 0.6606 - accuracy: 0.6196 - val_loss: 0.5731 - val_accuracy: 0.7931
Epoch 2/300
46/46 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6196 - val_loss: 0.5743 - val_accuracy: 0.7931
Epoch 3/300
46/46 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6196 - val_loss: 0.5714 - val_accuracy: 0.7931
중간 생략
Epoch 298/300
46/46 [==============================] - 0s 1ms/step - loss: 0.5925 - accuracy: 0.6783 - val_loss: 0.5847 - val_accuracy: 0.7500
Epoch 299/300
46/46 [==============================] - 0s 984us/step - loss: 0.5923 - accuracy: 0.6761 - val_loss: 0.5940 - val_accuracy: 0.7500
Epoch 300/300
46/46 [==============================] - 0s 987us/step - loss: 0.5930 - accuracy: 0.6826 - val_loss: 0.5613 - val_accuracy: 0.7759
'''
